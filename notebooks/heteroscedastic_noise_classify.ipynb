{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "plt.style.use('ggplot')\n",
    "import astropy.units as au\n",
    "import os\n",
    "\n",
    "import gpflow as gp\n",
    "from heterogp.latent import Latent\n",
    "from gpflow import settings\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s')\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.mplot3d\n",
    "import mpl_toolkits.mplot3d.axes3d as p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.actions import Loop, Action\n",
    "from gpflow.training import AdamOptimizer\n",
    "\n",
    "class PrintAction(Action):\n",
    "    def __init__(self, model, text):\n",
    "        self.model = model\n",
    "        self.text = text\n",
    "        \n",
    "    def run(self, ctx):\n",
    "        if ctx.iteration % 200 == 0:\n",
    "            likelihood = ctx.session.run(self.model.likelihood_tensor)\n",
    "            logging.warning('{}: iteration {} likelihood {:.4f}'.format(self.text, ctx.iteration, likelihood))\n",
    "    #         logging.warning(self.model)\n",
    "        \n",
    "def run_with_adam(model, lr,iterations, callback=None):\n",
    "    \n",
    "    adam = AdamOptimizer(lr).make_optimize_action(model)\n",
    "    \n",
    "    actions = [adam]#natgrad,\n",
    "    actions = actions if callback is None else actions + [callback]\n",
    "\n",
    "    Loop(actions, stop=iterations)()\n",
    "    model.anchor(model.enquire_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def draw(X, ys):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.scatter(\n",
    "        X[:,0].reshape(-1,1),\n",
    "        X[:,1].reshape(-1,1),\n",
    "        cmap=\"coolwarm\", \n",
    "        c=ys.reshape(-1,1))\n",
    "    plt.show()\n",
    "\n",
    "    table = pd.DataFrame(ys)\n",
    "    table.describe()\n",
    "    table[0].hist()\n",
    "    \n",
    "def acc_rate(ystar):\n",
    "    ypred = 1.*(ystar > 0.5)\n",
    "    acc = 1.-np.count_nonzero(ypred - Ytest) / Ytest.shape[0]\n",
    "    print('acc_rate', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some data with input-dependent noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(X):\n",
    "    return 1.*(X[:,0]**2 + (X[:,1]-1)**2 <= 0.5)\n",
    "\n",
    "def func_with_noise(X):\n",
    "    return 1.*(X[:,0]**2 + (X[:,1]-1)**2 + 0.1*np.random.normal(size=X.shape[0]) <= 0.5)\n",
    "\n",
    "N = 900\n",
    "Nn = 30\n",
    "\n",
    "k,b=np.mgrid[-1:1:30j,0:2:30j] # Nn\n",
    "f_kb=1.*(k**2 + (b-1)**2 + 0.1*np.random.normal(size=k.shape) <= 0.5)\n",
    "\n",
    "hk = np.hstack(k).reshape(-1, 1)\n",
    "hb = np.hstack(b).reshape(-1, 1)\n",
    "Xtrain = np.hstack((hk, hb))\n",
    "Ytrain = np.hstack(f_kb).reshape(-1, 1)\n",
    "\n",
    "draw(Xtrain, Ytrain)\n",
    "\n",
    "N, D = Xtrain.shape\n",
    "Xtest = np.random.random_sample((int(N*0.4), 2))*2+[-1, 0]\n",
    "Ytest = func(Xtest).reshape(-1,1)\n",
    "draw(Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the HGP model and train\n",
    "\n",
    "We will:\n",
    "  - Define the latent GP that models the noise\n",
    "  - Define heteroscedastic likelihood which uses the above latent\n",
    "  - Define the HGP which has another independent latent modelling the\n",
    "  underlying function\n",
    "  - Finally, train with Adam and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heterogp.likelihoods import HeteroscedasticGaussian\n",
    "from heterogp.hgp import HGP\n",
    "\n",
    "settings.numerics.jitter_level=1e-6\n",
    "iterations = 5000\n",
    "num_inducing = min(100, N/10) # TODO\n",
    "\n",
    "from scipy.cluster.vq import kmeans\n",
    "Z = kmeans(Xtrain, num_inducing)[0] \n",
    "# Z = np.linspace(-2,2,100)[:,None]\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    with gp.defer_build():       \n",
    "        \n",
    "        # Define the (log) noise latent\n",
    "        mean = gp.mean_functions.Constant(np.log(0.5))\n",
    "        kern = gp.kernels.RBF(D) # TODO\n",
    "        log_noise_latent = Latent(Z, mean, kern, num_latent=1, whiten=False, name=None)\n",
    "        # Define the likelihood\n",
    "        likelihood = HeteroscedasticGaussian(log_noise_latent)\n",
    "        log_noise_latent\n",
    "        # Define the underlying GP mean and kernel\n",
    "        mean = gp.mean_functions.Zero()\n",
    "        kernel = gp.kernels.RBF(D) # TODO\n",
    "        # Create the HGP (note the slightly different order from SVGP)\n",
    "        model = HGP(Xtrain, Ytrain, Z, kernel, likelihood, \n",
    "                     mean_function=mean, \n",
    "                     minibatch_size=500,\n",
    "                     num_latent = 1, \n",
    "                     num_samples=1,\n",
    "                     num_data=None,\n",
    "                     whiten=False)\n",
    "        model.compile()\n",
    "    from timeit import default_timer\n",
    "    t0 = default_timer()\n",
    "    run_with_adam(model,1e-3,iterations,PrintAction(model,\"Adam\"))\n",
    "    print(default_timer() - t0)\n",
    "    # Predictions uses stochastic sampling and produces \n",
    "    # [num_samples,N,D] shape output\n",
    "    ystar,varstar = model.predict_y(Xtest, 100)\n",
    "    # For plotting the noise\n",
    "    hetero_noise = model.likelihood.compute_hetero_noise(Xtest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_rate(ystar.mean(0))\n",
    "draw(Xtest, ystar.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "m = gp.models.SVGP(\n",
    "    Xtrain, Ytrain, kern=gp.kernels.RBF(2),\n",
    "    likelihood=gp.likelihoods.Bernoulli(), Z=Z)\n",
    "# Initially fix the hyperparameters.\n",
    "m.feature.set_trainable(False)\n",
    "gp.train.ScipyOptimizer().minimize(m, maxiter=iterations)\n",
    "\n",
    "# Unfix the hyperparameters.\n",
    "m.feature.set_trainable(True)\n",
    "gp.train.ScipyOptimizer(options=dict(maxiter=iterations)).minimize(m)\n",
    "ystar,varstar = m.predict_y(Xtest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "acc_rate(ystar)\n",
    "draw(Xtest, ystar[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.models.SGPR(\n",
    "    Xtrain, Ytrain, kern=gp.kernels.RBF(2), Z=Z)\n",
    "# Initially fix the hyperparameters.\n",
    "m.feature.set_trainable(False)\n",
    "gp.train.ScipyOptimizer().minimize(m, maxiter=iterations)\n",
    "\n",
    "# Unfix the hyperparameters.\n",
    "m.feature.set_trainable(True)\n",
    "gp.train.ScipyOptimizer(options=dict(maxiter=iterations)).minimize(m)\n",
    "ystar,varstar = m.predict_y(Xtest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_rate(ystar)\n",
    "draw(Xtest, ystar[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "80px",
    "width": "323px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 775.4,
   "position": {
    "height": "797px",
    "left": "1028.31px",
    "right": "20px",
    "top": "-22px",
    "width": "415.725px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
