{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "plt.style.use('ggplot')\n",
    "import astropy.units as au\n",
    "import os\n",
    "\n",
    "import gpflow as gp\n",
    "from heterogp.latent import Latent\n",
    "from gpflow import settings\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s')\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.actions import Loop, Action\n",
    "from gpflow.training import AdamOptimizer\n",
    "\n",
    "class PrintAction(Action):\n",
    "    def __init__(self, model, text):\n",
    "        self.model = model\n",
    "        self.text = text\n",
    "        \n",
    "    def run(self, ctx):\n",
    "        if ctx.iteration % 200 == 0:\n",
    "            likelihood = ctx.session.run(self.model.likelihood_tensor)\n",
    "            logging.warning('{}: iteration {} likelihood {:.4f}'.format(self.text, ctx.iteration, likelihood))\n",
    "    #         logging.warning(self.model)\n",
    "        \n",
    "def run_with_adam(model, lr,iterations, callback=None):\n",
    "    \n",
    "    adam = AdamOptimizer(lr).make_optimize_action(model)\n",
    "    \n",
    "    actions = [adam]#natgrad,\n",
    "    actions = actions if callback is None else actions + [callback]\n",
    "\n",
    "    Loop(actions, stop=iterations)()\n",
    "    model.anchor(model.enquire_session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def draw(X, ys):\n",
    "#     assert len(X.shape) != 2, 'draw matrix X'\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.ylabel(\"x2\")\n",
    "    plt.xlabel(\"x1\")\n",
    "    plt.scatter(\n",
    "        X[:,0].reshape(-1,1),\n",
    "        X[:,1].reshape(-1,1),\n",
    "        cmap=\"coolwarm\", \n",
    "        c=ys.reshape(-1,1))\n",
    "    plt.show()\n",
    "\n",
    "    table = pd.DataFrame(ys)\n",
    "    table.describe()\n",
    "    table[0].hist()\n",
    "    \n",
    "def acc_rate(ystar):\n",
    "    ypred = 1.*(ystar > 0.5)\n",
    "    acc = 1.-np.count_nonzero(ypred - Ytest) / Ytest.shape[0]\n",
    "    print('acc_rate', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define some data with input-dependent noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/gplab/gpmed')\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import multinomial\n",
    "\n",
    "from bayesian_benchmarks.data import get_classification_data\n",
    "from bayesian_benchmarks.models.get_model import get_classification_model\n",
    "from bayesian_benchmarks.database_utils import Database\n",
    "\n",
    "\n",
    "def parse_binary_data(fname, split):\n",
    "    data = get_classification_data(fname, split)\n",
    "    assert data.K == 2, 'binary classification'\n",
    "    return data.N, data.D, data.X_train, data.Y_train, data.X_test, data.Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D, Xtrain, Ytrain, Xtest, Ytest = parse_binary_data('heart-hungarian', split=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the HGP model and train\n",
    "\n",
    "We will:\n",
    "  - Define the latent GP that models the noise\n",
    "  - Define heteroscedastic likelihood which uses the above latent\n",
    "  - Define the HGP which has another independent latent modelling the\n",
    "  underlying function\n",
    "  - Finally, train with Adam and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heterogp.likelihoods import HeteroscedasticGaussian\n",
    "from heterogp.hgp import HGP\n",
    "\n",
    "settings.numerics.jitter_level=1e-6\n",
    "iterations = 5000\n",
    "num_inducing = np.int(min(100, N/10)) # TODO\n",
    "\n",
    "from scipy.cluster.vq import kmeans\n",
    "Z = kmeans(Xtrain, num_inducing)[0] \n",
    "# Z = np.linspace(-2,2,100)[:,None]\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    with gp.defer_build():       \n",
    "        \n",
    "        # Define the (log) noise latent\n",
    "        mean = gp.mean_functions.Constant(np.log(0.5))\n",
    "        kern = gp.kernels.RBF(D) # TODO\n",
    "        log_noise_latent = Latent(Z, mean, kern, num_latent=1, whiten=False, name=None)\n",
    "        # Define the likelihood\n",
    "        likelihood = HeteroscedasticGaussian(log_noise_latent)\n",
    "        log_noise_latent\n",
    "        # Define the underlying GP mean and kernel\n",
    "        mean = gp.mean_functions.Zero()\n",
    "        kernel = gp.kernels.RBF(D) # TODO\n",
    "        # Create the HGP (note the slightly different order from SVGP)\n",
    "        model = HGP(Xtrain, Ytrain, Z, kernel, likelihood, \n",
    "                     mean_function=mean, \n",
    "                     minibatch_size=500,\n",
    "                     num_latent = 1, \n",
    "                     num_samples=1,\n",
    "                     num_data=None,\n",
    "                     whiten=False)\n",
    "        model.compile()\n",
    "    from timeit import default_timer\n",
    "    t0 = default_timer()\n",
    "    run_with_adam(model,1e-3,iterations,PrintAction(model,\"Adam\"))\n",
    "    print(default_timer() - t0)\n",
    "    # Predictions uses stochastic sampling and produces \n",
    "    # [num_samples,N,D] shape output\n",
    "    ystar,varstar = model.predict_y(Xtest, 100)\n",
    "    # For plotting the noise\n",
    "    hetero_noise = model.likelihood.compute_hetero_noise(Xtest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_rate(ystar.mean(0))\n",
    "draw(Xtest, ystar.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "m = gp.models.SVGP(\n",
    "    Xtrain, Ytrain, kern=gp.kernels.RBF(2),\n",
    "    likelihood=gp.likelihoods.Bernoulli(), Z=Z)\n",
    "# Initially fix the hyperparameters.\n",
    "m.feature.set_trainable(False)\n",
    "gp.train.ScipyOptimizer().minimize(m, maxiter=iterations)\n",
    "\n",
    "# Unfix the hyperparameters.\n",
    "m.feature.set_trainable(True)\n",
    "gp.train.ScipyOptimizer(options=dict(maxiter=iterations)).minimize(m)\n",
    "ystar,varstar = m.predict_y(Xtest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "acc_rate(ystar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.models.SGPR(\n",
    "    Xtrain, Ytrain, kern=gp.kernels.RBF(2), Z=Z)\n",
    "# Initially fix the hyperparameters.\n",
    "m.feature.set_trainable(False)\n",
    "gp.train.ScipyOptimizer().minimize(m, maxiter=iterations)\n",
    "\n",
    "# Unfix the hyperparameters.\n",
    "m.feature.set_trainable(True)\n",
    "gp.train.ScipyOptimizer(options=dict(maxiter=iterations)).minimize(m)\n",
    "ystar,varstar = m.predict_y(Xtest, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_rate(ystar)\n",
    "draw(Xtest, ystar[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "80px",
    "width": "323px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 775.4,
   "position": {
    "height": "797px",
    "left": "909.3px",
    "right": "20px",
    "top": "-20px",
    "width": "579.125px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
